{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f369d279",
   "metadata": {},
   "source": [
    "Parameter Tuning for TV-Regularized Abel Inversion\n",
    "==================================================\n",
    "\n",
    "This example demonstrates the use of\n",
    "[scico.ray.tune](../_autosummary/scico.ray.tune.rst) to tune\n",
    "parameters for the companion [example script](ct_abel_tv_admm.rst). The\n",
    "`ray.tune` class API is used in this example.\n",
    "\n",
    "This script is hard-coded to run on CPU only to avoid the large number of\n",
    "warnings that are emitted when GPU resources are requested but not\n",
    "available, and due to the difficulty of supressing these warnings in a\n",
    "way that does not force use of the CPU only. To enable GPU usage, comment\n",
    "out the `os.environ` statements near the beginning of the script, and\n",
    "change the value of the \"gpu\" entry in the `resources` dict from 0 to 1.\n",
    "Note that two environment variables are set to suppress the warnings\n",
    "because `JAX_PLATFORMS` was intended to replace `JAX_PLATFORM_NAME` but\n",
    "this change has yet to be correctly implemented\n",
    "(see [google/jax#6805](https://github.com/google/jax/issues/6805) and\n",
    "[google/jax#10272](https://github.com/google/jax/pull/10272)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e1f53",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# isort: off\n",
    "import os\n",
    "\n",
    "os.environ[\"JAX_PLATFORM_NAME\"] = \"cpu\"\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import ray\n",
    "plot.config_notebook_plotting()\n",
    "\n",
    "ray.init(logging_level=logging.ERROR)  # need to call init before jax import: ray-project/ray#44087\n",
    "\n",
    "import scico.numpy as snp\n",
    "from scico import functional, linop, loss, metric, plot\n",
    "from scico.examples import create_circular_phantom\n",
    "from scico.linop.abel import AbelTransform\n",
    "from scico.optimize.admm import ADMM, LinearSubproblemSolver\n",
    "from scico.ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f9693",
   "metadata": {},
   "source": [
    "Create a ground truth image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70aefc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 256  # image size\n",
    "x_gt = create_circular_phantom((N, N), [0.4 * N, 0.2 * N, 0.1 * N], [1, 0, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d4a83",
   "metadata": {},
   "source": [
    "Set up the forward operator and create a test measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4647cbe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = AbelTransform(x_gt.shape)\n",
    "y = A @ x_gt\n",
    "np.random.seed(12345)\n",
    "y = y + np.random.normal(size=y.shape).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541c92e",
   "metadata": {},
   "source": [
    "Compute inverse Abel transform solution for use as initial solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae2938",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_inv = A.inverse(y)\n",
    "x0 = snp.clip(x_inv, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54836996",
   "metadata": {},
   "source": [
    "Define performance evaluation class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6bcf7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Trainable(tune.Trainable):\n",
    "    \"\"\"Parameter evaluation class.\"\"\"\n",
    "\n",
    "    def setup(self, config, x_gt, x0, y):\n",
    "        \"\"\"This method initializes a new parameter evaluation object. It\n",
    "        is called once when a new parameter evaluation object is created.\n",
    "        The `config` parameter is a dict of specific parameters for\n",
    "        evaluation of a single parameter set (a pair of parameters in\n",
    "        this case). The remaining parameters are objects that are passed\n",
    "        to the evaluation function via the ray object store.\n",
    "        \"\"\"\n",
    "        # Get arrays passed by tune call.\n",
    "        self.x_gt, self.x0, self.y = snp.array(x_gt), snp.array(x0), snp.array(y)\n",
    "        # Set up problem to be solved.\n",
    "        self.A = AbelTransform(self.x_gt.shape)\n",
    "        self.f = loss.SquaredL2Loss(y=self.y, A=self.A)\n",
    "        self.C = linop.FiniteDifference(input_shape=self.x_gt.shape)\n",
    "        self.reset_config(config)\n",
    "\n",
    "    def reset_config(self, config):\n",
    "        \"\"\"This method is only required when `scico.ray.tune.Tuner` is\n",
    "        initialized with `reuse_actors` set to ``True`` (the default). In\n",
    "        this case, a set of parameter evaluation processes and\n",
    "        corresponding objects are created once (including initialization\n",
    "        via a call to the `setup` method), and this method is called when\n",
    "        switching to evaluation of a different parameter configuration.\n",
    "        If `reuse_actors` is set to ``False``, then a new process and\n",
    "        object are created for each parameter configuration, and this\n",
    "        method is not used.\n",
    "        \"\"\"\n",
    "        # Extract solver parameters from config dict.\n",
    "        λ, ρ = config[\"lambda\"], config[\"rho\"]\n",
    "        # Set up parameter-dependent functional.\n",
    "        g = λ * functional.L1Norm()\n",
    "        # Define solver.\n",
    "        cg_tol = 1e-4\n",
    "        cg_maxiter = 25\n",
    "        self.solver = ADMM(\n",
    "            f=self.f,\n",
    "            g_list=[g],\n",
    "            C_list=[self.C],\n",
    "            rho_list=[ρ],\n",
    "            x0=self.x0,\n",
    "            maxiter=10,\n",
    "            subproblem_solver=LinearSubproblemSolver(\n",
    "                cg_kwargs={\"tol\": cg_tol, \"maxiter\": cg_maxiter}\n",
    "            ),\n",
    "        )\n",
    "        return True\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"This method is called for each step in the evaluation of a\n",
    "        single parameter configuration. The maximum number of times it\n",
    "        can be called is controlled by the `num_iterations` parameter\n",
    "        in the initialization of a `scico.ray.tune.Tuner` object.\n",
    "        \"\"\"\n",
    "        # Perform 10 solver steps for every ray.tune step\n",
    "        x_tv = snp.clip(self.solver.solve(), 0.0, 1.0)\n",
    "        return {\"psnr\": float(metric.psnr(self.x_gt, x_tv))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2abc2d",
   "metadata": {},
   "source": [
    "Define parameter search space and resources per trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce7b7f0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\"lambda\": tune.loguniform(1e0, 1e2), \"rho\": tune.loguniform(1e1, 1e3)}\n",
    "resources = {\"gpu\": 0, \"cpu\": 1}  # gpus per trial, cpus per trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4f2b0e",
   "metadata": {},
   "source": [
    "Run parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b640aa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuner = tune.Tuner(\n",
    "    tune.with_parameters(Trainable, x_gt=x_gt, x0=x0, y=y),\n",
    "    param_space=config,\n",
    "    resources=resources,\n",
    "    metric=\"psnr\",\n",
    "    mode=\"max\",\n",
    "    num_samples=100,  # perform 100 parameter evaluations\n",
    "    num_iterations=10,  # perform at most 10 steps for each parameter evaluation\n",
    ")\n",
    "results = tuner.fit()\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1391b6",
   "metadata": {},
   "source": [
    "Display best parameters and corresponding performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e88cea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_result = results.get_best_result()\n",
    "best_config = best_result.config\n",
    "print(f\"Best PSNR: {best_result.metrics['psnr']:.2f} dB\")\n",
    "print(\"Best config: \" + \", \".join([f\"{k}: {v:.2e}\" for k, v in best_config.items()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be0841",
   "metadata": {},
   "source": [
    "Plot parameter values visited during parameter search. Marker sizes are\n",
    "proportional to number of iterations run at each parameter pair. The best\n",
    "point in the parameter space is indicated in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b174b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plot.figure(figsize=(8, 8))\n",
    "trials = results.get_dataframe()\n",
    "for t in trials.iloc:\n",
    "    n = t[\"training_iteration\"]\n",
    "    plot.plot(\n",
    "        t[\"config/lambda\"],\n",
    "        t[\"config/rho\"],\n",
    "        ptyp=\"loglog\",\n",
    "        lw=0,\n",
    "        ms=(0.5 + 1.5 * n),\n",
    "        marker=\"o\",\n",
    "        mfc=\"blue\",\n",
    "        mec=\"blue\",\n",
    "        fig=fig,\n",
    "    )\n",
    "plot.plot(\n",
    "    best_config[\"lambda\"],\n",
    "    best_config[\"rho\"],\n",
    "    ptyp=\"loglog\",\n",
    "    title=\"Parameter search sampling locations\\n(marker size proportional to number of iterations)\",\n",
    "    xlbl=r\"$\\rho$\",\n",
    "    ylbl=r\"$\\lambda$\",\n",
    "    lw=0,\n",
    "    ms=5.0,\n",
    "    marker=\"o\",\n",
    "    mfc=\"red\",\n",
    "    mec=\"red\",\n",
    "    fig=fig,\n",
    ")\n",
    "ax = fig.axes[0]\n",
    "ax.set_xlim([config[\"rho\"].lower, config[\"rho\"].upper])\n",
    "ax.set_ylim([config[\"lambda\"].lower, config[\"lambda\"].upper])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd5358e",
   "metadata": {},
   "source": [
    "Plot parameter values visited during parameter search and corresponding\n",
    "reconstruction PSNRs.The best point in the parameter space is indicated\n",
    "in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b58973",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "𝜌 = [t[\"config/rho\"] for t in trials.iloc]\n",
    "𝜆 = [t[\"config/lambda\"] for t in trials.iloc]\n",
    "psnr = [t[\"psnr\"] for t in trials.iloc]\n",
    "minpsnr = min(max(psnr), 20.0)\n",
    "𝜌, 𝜆, psnr = zip(*filter(lambda x: x[2] >= minpsnr, zip(𝜌, 𝜆, psnr)))\n",
    "fig, ax = plot.subplots(figsize=(10, 8))\n",
    "sc = ax.scatter(𝜌, 𝜆, c=psnr, cmap=plot.cm.plasma_r)\n",
    "fig.colorbar(sc)\n",
    "plot.plot(\n",
    "    best_config[\"lambda\"],\n",
    "    best_config[\"rho\"],\n",
    "    ptyp=\"loglog\",\n",
    "    lw=0,\n",
    "    ms=12.0,\n",
    "    marker=\"2\",\n",
    "    mfc=\"red\",\n",
    "    mec=\"red\",\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(r\"$\\rho$\")\n",
    "ax.set_ylabel(r\"$\\lambda$\")\n",
    "ax.set_title(\"PSNR at each sample location\\n(values below 20 dB omitted)\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
