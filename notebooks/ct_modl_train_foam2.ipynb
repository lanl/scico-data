{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "340a580b",
   "metadata": {},
   "source": [
    "CT Training and Reconstruction with MoDL\n",
    "========================================\n",
    "\n",
    "This example demonstrates the training and application of a\n",
    "model-based deep learning (MoDL) architecture described in\n",
    "<cite data-cite=\"aggarwal-2019-modl\"/> applied to a CT reconstruction problem.\n",
    "\n",
    "The source images are foam phantoms generated with xdesign.\n",
    "\n",
    "A class\n",
    "[scico.flax.MoDLNet](../_autosummary/scico.flax.rst#scico.flax.MoDLNet)\n",
    "implements the MoDL architecture, which solves the optimization\n",
    "problem\n",
    "\n",
    "$$\\mathrm{argmin}_{\\mathbf{x}} \\; \\| A \\mathbf{x} - \\mathbf{y} \\|_2^2\n",
    "+ \\lambda \\, \\| \\mathbf{x} - \\mathrm{D}_w(\\mathbf{x})\\|_2^2 \\;,$$\n",
    "\n",
    "where $A$ is a tomographic projector, $\\mathbf{y}$ is a set of sinograms,\n",
    "$\\mathrm{D}_w$ is the regularization (a denoiser), and $\\mathbf{x}$ is\n",
    "the set of reconstructed images. The MoDL abstracts the iterative\n",
    "solution by an unrolled network where each iteration corresponds to a\n",
    "different stage in the MoDL network and updates the prediction by solving\n",
    "\n",
    "$$\\mathbf{x}^{k+1} = (A^T A + \\lambda \\, I)^{-1} (A^T \\mathbf{y} +\n",
    "\\lambda \\, \\mathbf{z}^k) \\;,$$\n",
    "\n",
    "via conjugate gradient. In the expression, $k$ is the index of the stage\n",
    "(iteration), $\\mathbf{z}^k = \\mathrm{ResNet}(\\mathbf{x}^{k})$ is the\n",
    "regularization (a denoiser implemented as a residual convolutional neural\n",
    "network), $\\mathbf{x}^k$ is the output of the previous stage,\n",
    "$\\lambda > 0$ is a learned regularization parameter, and $I$ is the\n",
    "identity operator. The output of the final stage is the set of\n",
    "reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9395788f",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:50:28.598142Z",
     "iopub.status.busy": "2024-10-11T21:50:28.597771Z",
     "iopub.status.idle": "2024-10-11T21:51:33.620214Z",
     "shell.execute_reply": "2024-10-11T21:51:33.618876Z"
    }
   },
   "outputs": [],
   "source": [
    "# isort: off\n",
    "import os\n",
    "from functools import partial\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "import ray\n",
    "\n",
    "ray.init(logging_level=logging.ERROR)  # need to call init before jax import: ray-project/ray#44087\n",
    "\n",
    "import jax\n",
    "\n",
    "try:\n",
    "    from jax.extend.backend import get_backend  # introduced in jax 0.4.33\n",
    "except ImportError:\n",
    "    from jax.lib.xla_bridge import get_backend\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from scico import flax as sflax\n",
    "from scico import metric, plot\n",
    "from scico.flax.examples import load_ct_data\n",
    "from scico.flax.train.traversals import clip_positive, construct_traversal\n",
    "from scico.linop.xray import XRayTransform2D\n",
    "plot.config_notebook_plotting()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ee098",
   "metadata": {},
   "source": [
    "Prepare parallel processing. Set an arbitrary processor count (only\n",
    "applies if GPU is not available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1397172e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:33.623511Z",
     "iopub.status.busy": "2024-10-11T21:51:33.623010Z",
     "iopub.status.idle": "2024-10-11T21:51:33.627548Z",
     "shell.execute_reply": "2024-10-11T21:51:33.626873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform:  gpu\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
    "platform = get_backend().platform\n",
    "print(\"Platform: \", platform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db79059",
   "metadata": {},
   "source": [
    "Read data from cache or generate if not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4dca662",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:33.629766Z",
     "iopub.status.busy": "2024-10-11T21:51:33.629265Z",
     "iopub.status.idle": "2024-10-11T21:51:34.239718Z",
     "shell.execute_reply": "2024-10-11T21:51:34.238467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read from path: ~/.cache/scico/examples/data\n",
      "Set --training-- size: 536\n",
      "Set --testing -- size: 64\n",
      "Data range --images  --  Min:  0.00  Max:  1.00\n",
      "Data range --sinogram--  Min: -0.00  Max:  0.95\n",
      "Data range --FBP     --  Min:  0.00  Max:  1.00\n"
     ]
    }
   ],
   "source": [
    "N = 256  # phantom size\n",
    "train_nimg = 536  # number of training images\n",
    "test_nimg = 64  # number of testing images\n",
    "nimg = train_nimg + test_nimg\n",
    "n_projection = 45  # CT views\n",
    "\n",
    "trdt, ttdt = load_ct_data(train_nimg, test_nimg, N, n_projection, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a96566e",
   "metadata": {},
   "source": [
    "Build CT projection operator. Parameters are chosen so that the operator\n",
    "is equivalent to the one used to generate the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d59053",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.242268Z",
     "iopub.status.busy": "2024-10-11T21:51:34.241884Z",
     "iopub.status.idle": "2024-10-11T21:51:34.749352Z",
     "shell.execute_reply": "2024-10-11T21:51:34.748272Z"
    }
   },
   "outputs": [],
   "source": [
    "angles = np.linspace(0, np.pi, n_projection)  # evenly spaced projection angles\n",
    "A = XRayTransform2D(\n",
    "    input_shape=(N, N),\n",
    "    angles=angles,\n",
    "    det_count=int(N * 1.05 / np.sqrt(2.0)),\n",
    "    dx=1.0 / np.sqrt(2),\n",
    ")\n",
    "A = (1.0 / N) * A  # normalize projection operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9a3114",
   "metadata": {},
   "source": [
    "Build training and testing structures. Inputs are the sinograms and\n",
    "outputs are the original generated foams. Keep training and testing\n",
    "partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9c2731",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.752142Z",
     "iopub.status.busy": "2024-10-11T21:51:34.751759Z",
     "iopub.status.idle": "2024-10-11T21:51:34.755510Z",
     "shell.execute_reply": "2024-10-11T21:51:34.754895Z"
    }
   },
   "outputs": [],
   "source": [
    "numtr = 100\n",
    "numtt = 16\n",
    "train_ds = {\"image\": trdt[\"sino\"][:numtr], \"label\": trdt[\"img\"][:numtr]}\n",
    "test_ds = {\"image\": ttdt[\"sino\"][:numtt], \"label\": ttdt[\"img\"][:numtt]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb6fa9",
   "metadata": {},
   "source": [
    "Define configuration dictionary for model and training loop.\n",
    "\n",
    "Parameters have been selected for demonstration purposes and\n",
    "relatively short training. The model depth is akin to the number of\n",
    "unrolled iterations in the MoDL model. The block depth controls the\n",
    "number of layers at each unrolled iteration. The number of filters is\n",
    "uniform throughout the iterations. The iterations used for the\n",
    "conjugate gradient (CG) solver can also be specified. Better\n",
    "performance may be obtained by increasing depth, block depth, number\n",
    "of filters, CG iterations, or training epochs, but may require longer\n",
    "training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1490aa2",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.757497Z",
     "iopub.status.busy": "2024-10-11T21:51:34.757237Z",
     "iopub.status.idle": "2024-10-11T21:51:34.760542Z",
     "shell.execute_reply": "2024-10-11T21:51:34.759918Z"
    }
   },
   "outputs": [],
   "source": [
    "# model configuration\n",
    "model_conf = {\n",
    "    \"depth\": 10,\n",
    "    \"num_filters\": 64,\n",
    "    \"block_depth\": 4,\n",
    "    \"cg_iter_1\": 3,\n",
    "    \"cg_iter_2\": 8,\n",
    "}\n",
    "# training configuration\n",
    "train_conf: sflax.ConfigDict = {\n",
    "    \"seed\": 12345,\n",
    "    \"opt_type\": \"SGD\",\n",
    "    \"momentum\": 0.9,\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 20,\n",
    "    \"base_learning_rate\": 1e-2,\n",
    "    \"warmup_epochs\": 0,\n",
    "    \"log_every_steps\": 40,\n",
    "    \"log\": True,\n",
    "    \"checkpointing\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bc60ac",
   "metadata": {},
   "source": [
    "Construct functionality for ensuring that the learned\n",
    "regularization parameter is always positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6392422",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.762795Z",
     "iopub.status.busy": "2024-10-11T21:51:34.762267Z",
     "iopub.status.idle": "2024-10-11T21:51:34.765370Z",
     "shell.execute_reply": "2024-10-11T21:51:34.764690Z"
    }
   },
   "outputs": [],
   "source": [
    "lmbdatrav = construct_traversal(\"lmbda\")  # select lmbda parameters in model\n",
    "lmbdapos = partial(\n",
    "    clip_positive,  # apply this function\n",
    "    traversal=lmbdatrav,  # to lmbda parameters in model\n",
    "    minval=5e-4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871a950",
   "metadata": {},
   "source": [
    "Print configuration of distributed run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee1846d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.767672Z",
     "iopub.status.busy": "2024-10-11T21:51:34.767077Z",
     "iopub.status.idle": "2024-10-11T21:51:34.770678Z",
     "shell.execute_reply": "2024-10-11T21:51:34.770027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "JAX process: 0 / 1\n",
      "JAX local devices: [CudaDevice(id=0), CudaDevice(id=1), CudaDevice(id=2), CudaDevice(id=3), CudaDevice(id=4), CudaDevice(id=5), CudaDevice(id=6), CudaDevice(id=7)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nJAX process: {jax.process_index()}{' / '}{jax.process_count()}\")\n",
    "print(f\"JAX local devices: {jax.local_devices()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29cc25d",
   "metadata": {},
   "source": [
    "Check for iterated trained model. If not found, construct MoDLNet\n",
    "model, using only one iteration (depth) in model and few CG iterations\n",
    "for faster intialization. Run first stage (initialization) training\n",
    "loop followed by a second stage (depth iterations) training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6775a15",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:51:34.772983Z",
     "iopub.status.busy": "2024-10-11T21:51:34.772392Z",
     "iopub.status.idle": "2024-10-11T21:55:45.031812Z",
     "shell.execute_reply": "2024-10-11T21:55:45.030379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels: 1   training signals: 100   testing signals: 16   signal size: 256\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure:\n",
      "+------------------------------------------+----------------+--------+----------+--------+\n",
      "| Name                                     | Shape          | Size   | Mean     | Std    |\n",
      "+------------------------------------------+----------------+--------+----------+--------+\n",
      "| ResNet_0/BatchNorm_0/bias                | (1,)           | 1      | 0.0      | 0.0    |\n",
      "| ResNet_0/BatchNorm_0/scale               | (1,)           | 1      | 1.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/bias  | (64,)          | 64     | 0.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/scale | (64,)          | 64     | 1.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_0/Conv_0/kernel     | (3, 3, 1, 64)  | 576    | 0.0023   | 0.058  |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/bias  | (64,)          | 64     | 0.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/scale | (64,)          | 64     | 1.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_1/Conv_0/kernel     | (3, 3, 64, 64) | 36,864 | 0.000156 | 0.0417 |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/bias  | (64,)          | 64     | 0.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/scale | (64,)          | 64     | 1.0      | 0.0    |\n",
      "| ResNet_0/ConvBNBlock_2/Conv_0/kernel     | (3, 3, 64, 64) | 36,864 | 0.000153 | 0.0418 |\n",
      "| ResNet_0/Conv_0/kernel                   | (3, 3, 64, 1)  | 576    | -0.00192 | 0.0585 |\n",
      "| lmbda                                    | (1,)           | 1      | 0.5      | 0.0    |\n",
      "+------------------------------------------+----------------+--------+----------+--------+\n",
      "Total weights: 75,267\n",
      "\n",
      "Batch Normalization:\n",
      "+-----------------------------------------+-------+------+------+-----+\n",
      "| Name                                    | Shape | Size | Mean | Std |\n",
      "+-----------------------------------------+-------+------+------+-----+\n",
      "| ResNet_0/BatchNorm_0/mean               | (1,)  | 1    | 0.0  | 0.0 |\n",
      "| ResNet_0/BatchNorm_0/var                | (1,)  | 1    | 1.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/mean | (64,) | 64   | 0.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/var  | (64,) | 64   | 1.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/mean | (64,) | 64   | 0.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/var  | (64,) | 64   | 1.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/mean | (64,) | 64   | 0.0  | 0.0 |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/var  | (64,) | 64   | 1.0  | 0.0 |\n",
      "+-----------------------------------------+-------+------+------+-----+\n",
      "Total weights: 386\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial compilation, which might take some time ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial compilation completed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  Time      Train_LR  Train_Loss  Train_SNR  Eval_Loss  Eval_SNR\n",
      "---------------------------------------------------------------------\n",
      "    6  5.60e+00  0.010000    0.090173      -0.56   0.036267      0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13  7.48e+00  0.010000    0.018096       4.06   0.036421      0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19  8.15e+00  0.010000    0.015272       4.79   0.036610      0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoDLNet init      epochs:   20   time[s]:               10.26\n",
      "channels: 1   training signals: 100   testing signals: 16   signal size: 256\n",
      "\n",
      "Network Structure:\n",
      "+------------------------------------------+----------------+--------+-----------+---------+\n",
      "| Name                                     | Shape          | Size   | Mean      | Std     |\n",
      "+------------------------------------------+----------------+--------+-----------+---------+\n",
      "| ResNet_0/BatchNorm_0/bias                | (1,)           | 1      | 0.237     | 0.0     |\n",
      "| ResNet_0/BatchNorm_0/scale               | (1,)           | 1      | 0.235     | 0.0     |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/bias  | (64,)          | 64     | -0.00032  | 0.00547 |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/scale | (64,)          | 64     | 1.0       | 0.00267 |\n",
      "| ResNet_0/ConvBNBlock_0/Conv_0/kernel     | (3, 3, 1, 64)  | 576    | -0.00143  | 0.06    |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/bias  | (64,)          | 64     | -8.6e-05  | 0.00206 |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/scale | (64,)          | 64     | 1.0       | 0.00194 |\n",
      "| ResNet_0/ConvBNBlock_1/Conv_0/kernel     | (3, 3, 64, 64) | 36,864 | 0.000158  | 0.0418  |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/bias  | (64,)          | 64     | -1.92e-05 | 0.002   |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/scale | (64,)          | 64     | 1.0       | 0.00215 |\n",
      "| ResNet_0/ConvBNBlock_2/Conv_0/kernel     | (3, 3, 64, 64) | 36,864 | 0.000108  | 0.0418  |\n",
      "| ResNet_0/Conv_0/kernel                   | (3, 3, 64, 1)  | 576    | 0.00173   | 0.0593  |\n",
      "| lmbda                                    | (1,)           | 1      | 0.331     | 0.0     |\n",
      "+------------------------------------------+----------------+--------+-----------+---------+\n",
      "Total weights: 75,267\n",
      "\n",
      "Batch Normalization:\n",
      "+-----------------------------------------+-------+------+-----------+----------+\n",
      "| Name                                    | Shape | Size | Mean      | Std      |\n",
      "+-----------------------------------------+-------+------+-----------+----------+\n",
      "| ResNet_0/BatchNorm_0/mean               | (1,)  | 1    | 0.13      | 0.0      |\n",
      "| ResNet_0/BatchNorm_0/var                | (1,)  | 1    | 3.16      | 0.0      |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/mean | (64,) | 64   | -0.000556 | 0.0114   |\n",
      "| ResNet_0/ConvBNBlock_0/BatchNorm_0/var  | (64,) | 64   | 0.299     | 1.28e-05 |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/mean | (64,) | 64   | 0.00708   | 0.238    |\n",
      "| ResNet_0/ConvBNBlock_1/BatchNorm_0/var  | (64,) | 64   | 0.596     | 0.601    |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/mean | (64,) | 64   | 0.0227    | 0.307    |\n",
      "| ResNet_0/ConvBNBlock_2/BatchNorm_0/var  | (64,) | 64   | 0.654     | 0.371    |\n",
      "+-----------------------------------------+-------+------+-----------+----------+\n",
      "Total weights: 386\n",
      "\n",
      "Initial compilation, which might take some time ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial compilation completed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  Time      Train_LR  Train_Loss  Train_SNR  Eval_Loss  Eval_SNR\n",
      "---------------------------------------------------------------------\n",
      "    6  2.23e+01  0.010000    0.132514      -0.76   0.021762      3.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   13  3.53e+01  0.010000    0.019889       3.63   0.019905      3.59\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   19  4.50e+01  0.010000    0.018389       3.97   0.018836      3.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   26  5.48e+01  0.010000    0.017589       4.16   0.018233      3.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   33  6.47e+01  0.010000    0.016500       4.45   0.016175      4.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   39  7.45e+01  0.010000    0.013259       5.44   0.008942      7.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   46  8.45e+01  0.010000    0.007994       7.60   0.007488      7.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   53  9.44e+01  0.010000    0.006613       8.42   0.006694      8.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59  1.04e+02  0.010000    0.005603       9.13   0.006511      8.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   66  1.14e+02  0.010000    0.005067       9.57   0.005744      8.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   73  1.24e+02  0.010000    0.004694       9.90   0.005274      9.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   79  1.34e+02  0.010000    0.004434      10.15   0.004814      9.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   86  1.44e+02  0.010000    0.004157      10.43   0.004694      9.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   93  1.54e+02  0.010000    0.003954      10.64   0.004373     10.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   99  1.63e+02  0.010000    0.003776      10.84   0.004282     10.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  106  1.73e+02  0.010000    0.003657      10.99   0.004314     10.23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  113  1.83e+02  0.010000    0.003540      11.12   0.004279     10.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  119  1.93e+02  0.010000    0.003409      11.29   0.003989     10.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  126  2.03e+02  0.010000    0.003374      11.33   0.004094     10.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  133  2.13e+02  0.010000    0.003220      11.54   0.003947     10.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  139  2.23e+02  0.010000    0.003127      11.66   0.004016     10.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  146  2.33e+02  0.010000    0.003054      11.76   0.004811      9.75\n"
     ]
    }
   ],
   "source": [
    "channels = train_ds[\"image\"].shape[-1]\n",
    "workdir2 = os.path.join(\n",
    "    os.path.expanduser(\"~\"), \".cache\", \"scico\", \"examples\", \"modl_ct_out\", \"iterated\"\n",
    ")\n",
    "\n",
    "stats_object_ini = None\n",
    "stats_object = None\n",
    "\n",
    "checkpoint_files = []\n",
    "for dirpath, dirnames, filenames in os.walk(workdir2):\n",
    "    checkpoint_files = [fn for fn in filenames]\n",
    "\n",
    "if len(checkpoint_files) > 0:\n",
    "    model = sflax.MoDLNet(\n",
    "        operator=A,\n",
    "        depth=model_conf[\"depth\"],\n",
    "        channels=channels,\n",
    "        num_filters=model_conf[\"num_filters\"],\n",
    "        block_depth=model_conf[\"block_depth\"],\n",
    "        cg_iter=model_conf[\"cg_iter_2\"],\n",
    "    )\n",
    "\n",
    "    train_conf[\"post_lst\"] = [lmbdapos]\n",
    "    # Parameters for 2nd stage\n",
    "    train_conf[\"workdir\"] = workdir2\n",
    "    train_conf[\"opt_type\"] = \"ADAM\"\n",
    "    train_conf[\"num_epochs\"] = 150\n",
    "    # Construct training object\n",
    "    trainer = sflax.BasicFlaxTrainer(\n",
    "        train_conf,\n",
    "        model,\n",
    "        train_ds,\n",
    "        test_ds,\n",
    "    )\n",
    "    start_time = time()\n",
    "    modvar, stats_object = trainer.train()\n",
    "    time_train = time() - start_time\n",
    "    time_init = 0.0\n",
    "    epochs_init = 0\n",
    "else:\n",
    "    # One iteration (depth) in model and few CG iterations\n",
    "    model = sflax.MoDLNet(\n",
    "        operator=A,\n",
    "        depth=1,\n",
    "        channels=channels,\n",
    "        num_filters=model_conf[\"num_filters\"],\n",
    "        block_depth=model_conf[\"block_depth\"],\n",
    "        cg_iter=model_conf[\"cg_iter_1\"],\n",
    "    )\n",
    "    # First stage: initialization training loop.\n",
    "    workdir1 = os.path.join(os.path.expanduser(\"~\"), \".cache\", \"scico\", \"examples\", \"modl_ct_out\")\n",
    "    train_conf[\"workdir\"] = workdir1\n",
    "    train_conf[\"post_lst\"] = [lmbdapos]\n",
    "    # Construct training object\n",
    "    trainer = sflax.BasicFlaxTrainer(\n",
    "        train_conf,\n",
    "        model,\n",
    "        train_ds,\n",
    "        test_ds,\n",
    "    )\n",
    "\n",
    "    start_time = time()\n",
    "    modvar, stats_object_ini = trainer.train()\n",
    "    time_init = time() - start_time\n",
    "    epochs_init = train_conf[\"num_epochs\"]\n",
    "\n",
    "    print(\n",
    "        f\"{'MoDLNet init':18s}{'epochs:':2s}{train_conf['num_epochs']:>5d}{'':3s}\"\n",
    "        f\"{'time[s]:':21s}{time_init:>7.2f}\"\n",
    "    )\n",
    "\n",
    "    # Second stage: depth iterations training loop.\n",
    "    model.depth = model_conf[\"depth\"]\n",
    "    model.cg_iter = model_conf[\"cg_iter_2\"]\n",
    "    train_conf[\"opt_type\"] = \"ADAM\"\n",
    "    train_conf[\"num_epochs\"] = 150\n",
    "    train_conf[\"workdir\"] = workdir2\n",
    "    # Construct training object, include current model parameters\n",
    "    trainer = sflax.BasicFlaxTrainer(\n",
    "        train_conf,\n",
    "        model,\n",
    "        train_ds,\n",
    "        test_ds,\n",
    "        variables0=modvar,\n",
    "    )\n",
    "    start_time = time()\n",
    "    modvar, stats_object = trainer.train()\n",
    "    time_train = time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c21a9",
   "metadata": {},
   "source": [
    "Evaluate on testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ed7378",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:55:45.036142Z",
     "iopub.status.busy": "2024-10-11T21:55:45.035601Z",
     "iopub.status.idle": "2024-10-11T21:55:51.449394Z",
     "shell.execute_reply": "2024-10-11T21:55:51.447714Z"
    }
   },
   "outputs": [],
   "source": [
    "del train_ds[\"image\"]\n",
    "del train_ds[\"label\"]\n",
    "\n",
    "fmap = sflax.FlaxMap(model, modvar)\n",
    "del model, modvar\n",
    "\n",
    "maxn = numtt\n",
    "start_time = time()\n",
    "output = fmap(test_ds[\"image\"][:maxn])\n",
    "time_eval = time() - start_time\n",
    "output = np.clip(output, a_min=0, a_max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72d031d",
   "metadata": {},
   "source": [
    "Evaluate trained model in terms of reconstruction time\n",
    "and data fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a563bace",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:55:51.452755Z",
     "iopub.status.busy": "2024-10-11T21:55:51.452344Z",
     "iopub.status.idle": "2024-10-11T21:55:51.994260Z",
     "shell.execute_reply": "2024-10-11T21:55:51.993098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoDLNet training  epochs:  170                     time[s]:   248.08\n",
      "MoDLNet testing   SNR: 10.40 dB   PSNR: 20.81 dB   time[s]:     6.34\n"
     ]
    }
   ],
   "source": [
    "total_epochs = epochs_init + train_conf[\"num_epochs\"]\n",
    "total_time_train = time_init + time_train\n",
    "snr_eval = metric.snr(test_ds[\"label\"][:maxn], output)\n",
    "psnr_eval = metric.psnr(test_ds[\"label\"][:maxn], output)\n",
    "print(\n",
    "    f\"{'MoDLNet training':18s}{'epochs:':2s}{total_epochs:>5d}{'':21s}\"\n",
    "    f\"{'time[s]:':10s}{total_time_train:>7.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'MoDLNet testing':18s}{'SNR:':5s}{snr_eval:>5.2f}{' dB'}{'':3s}\"\n",
    "    f\"{'PSNR:':6s}{psnr_eval:>5.2f}{' dB'}{'':3s}{'time[s]:':10s}{time_eval:>7.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05534e9e",
   "metadata": {},
   "source": [
    "Plot comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec5e1988",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:55:51.996778Z",
     "iopub.status.busy": "2024-10-11T21:55:51.996464Z",
     "iopub.status.idle": "2024-10-11T21:55:52.508416Z",
     "shell.execute_reply": "2024-10-11T21:55:52.507227Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "indx = np.random.randint(0, high=maxn)\n",
    "\n",
    "fig, ax = plot.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "plot.imview(test_ds[\"label\"][indx, ..., 0], title=\"Ground truth\", cbar=None, fig=fig, ax=ax[0])\n",
    "plot.imview(\n",
    "    test_ds[\"image\"][indx, ..., 0],\n",
    "    title=\"Sinogram\",\n",
    "    cbar=None,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "plot.imview(\n",
    "    output[indx, ..., 0],\n",
    "    title=\"MoDLNet Reconstruction\\nSNR: %.2f (dB), PSNR: %.2f\"\n",
    "    % (\n",
    "        metric.snr(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "        metric.psnr(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "    ),\n",
    "    fig=fig,\n",
    "    ax=ax[2],\n",
    ")\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "fig.colorbar(ax[2].get_images()[0], cax=cax, label=\"arbitrary units\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689d815",
   "metadata": {},
   "source": [
    "Plot convergence statistics. Statistics are generated only if a training\n",
    "cycle was done (i.e. if not reading final epoch results from checkpoint)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bae59f1",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-10-11T21:55:52.511188Z",
     "iopub.status.busy": "2024-10-11T21:55:52.510814Z",
     "iopub.status.idle": "2024-10-11T21:55:52.888798Z",
     "shell.execute_reply": "2024-10-11T21:55:52.887662Z"
    }
   },
   "outputs": [],
   "source": [
    "if stats_object is not None and len(stats_object.iterations) > 0:\n",
    "    hist = stats_object.history(transpose=True)\n",
    "    fig, ax = plot.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    plot.plot(\n",
    "        np.vstack((hist.Train_Loss, hist.Eval_Loss)).T,\n",
    "        x=hist.Epoch,\n",
    "        ptyp=\"semilogy\",\n",
    "        title=\"Loss function\",\n",
    "        xlbl=\"Epoch\",\n",
    "        ylbl=\"Loss value\",\n",
    "        lgnd=(\"Train\", \"Test\"),\n",
    "        fig=fig,\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    plot.plot(\n",
    "        np.vstack((hist.Train_SNR, hist.Eval_SNR)).T,\n",
    "        x=hist.Epoch,\n",
    "        title=\"Metric\",\n",
    "        xlbl=\"Epoch\",\n",
    "        ylbl=\"SNR (dB)\",\n",
    "        lgnd=(\"Train\", \"Test\"),\n",
    "        fig=fig,\n",
    "        ax=ax[1],\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Stats for initialization loop\n",
    "if stats_object_ini is not None and len(stats_object_ini.iterations) > 0:\n",
    "    hist = stats_object_ini.history(transpose=True)\n",
    "    fig, ax = plot.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "    plot.plot(\n",
    "        np.vstack((hist.Train_Loss, hist.Eval_Loss)).T,\n",
    "        ptyp=\"semilogy\",\n",
    "        title=\"Loss function - Initialization\",\n",
    "        xlbl=\"Epoch\",\n",
    "        ylbl=\"Loss value\",\n",
    "        lgnd=(\"Train\", \"Test\"),\n",
    "        fig=fig,\n",
    "        ax=ax[0],\n",
    "    )\n",
    "    plot.plot(\n",
    "        np.vstack((hist.Train_SNR, hist.Eval_SNR)).T,\n",
    "        title=\"Metric - Initialization\",\n",
    "        xlbl=\"Epoch\",\n",
    "        ylbl=\"SNR (dB)\",\n",
    "        lgnd=(\"Train\", \"Test\"),\n",
    "        fig=fig,\n",
    "        ax=ax[1],\n",
    "    )\n",
    "    fig.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
