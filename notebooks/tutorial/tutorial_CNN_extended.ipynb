{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0ef3f7",
   "metadata": {},
   "source": [
    "# Example: Data-Driven Priors for Inverse Problems\n",
    "\n",
    "In this example,\n",
    " we will explore how to use CNN models as data-driven priors in a SCICO pipeline for performing computed tomography (CT) reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f56ee8",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To set up your environment, run the cell below.\n",
    "\n",
    "If you get a popup with 'Warning: This notebook was not authored by Google.', select 'Run anyway'.\n",
    "You should see console outputs appearing.\n",
    "The install may take several minutes;\n",
    "when it is finished, you should see `==done with install==`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da49c7f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install -q condacolab\n",
    "import condacolab\n",
    "condacolab.install()\n",
    "\n",
    "!pip install git+https://github.com/lanl/scico@cristina/more-flax\n",
    "!pip install xdesign\n",
    "!conda install -c astra-toolbox astra-toolbox\n",
    "\n",
    "print('==done with install==')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d467dbfc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Suppose that you are performing CT scans of many similar objects\n",
    " and want to construct a pipeline to rapidly compute the reconstruction\n",
    " of each new measurement.\n",
    "For this example, we will use computer-generated foam images\n",
    "as the objects we want to image.\n",
    "Run the next cell to generate and visualize one of such foams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916a6b3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from xdesign import Foam, discrete_phantom\n",
    "\n",
    "from scico import plot\n",
    "\n",
    "plot.config_notebook_plotting()  # set up plotting\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"  # set default colormap\n",
    "\n",
    "np.random.seed(7654)\n",
    "\n",
    "N = 256  # image size\n",
    "x_fm = discrete_phantom(Foam(size_range=[0.075, 0.0025], gap=1e-3, porosity=1), size=N)\n",
    "x_gt = x_fm / np.max(x_fm)\n",
    "x_gt = np.clip(x_gt, 0, 1.0)\n",
    "\n",
    "# Plot signal\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_gt)\n",
    "ax.set_title(\"Foam\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175ce4f",
   "metadata": {},
   "source": [
    "This image shows one foam,\n",
    " but data-driven pipelines assume that you have access to a wealth of relevant data.\n",
    " Let's generate several different foams to use in our CT reconstruction pipeline.\n",
    " Since we are interested in CT reconstruction, we need to generate both images and sinograms.\n",
    "\n",
    "SCICO provides CT projectors based on Python libraries such as ASTRA and SVMBIR. In this case we will use the\n",
    "ASTRA interface (see https://scico.readthedocs.io/en/latest/_autosummary/scico.linop.radon_astra.html).\n",
    "\n",
    "**Define an ASTRA SCICO CT projector assuming 60 equally spaced projections.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576471f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_projection = ...  # number of projections\n",
    "angles = ...\n",
    "A = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ddfbda",
   "metadata": {},
   "source": [
    "Machine learning algorithms are typically very sensitive to the scaling of their inputs.\n",
    "For this reason, we normalize the operator `A` by the dimension of the image,\n",
    "which, for this operator, makes $ ||Ax|| \\approx ||x||$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83098249",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = A / N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43ed39",
   "metadata": {},
   "source": [
    "**Test your operator by computing the sinogram of the generated foam and plotting your results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778cae23",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "sino = ...\n",
    "\n",
    "fig, ax = plot.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "plot.imview(..., title=\"Ground truth\", cbar=None, fig=fig, ax=ax[0])\n",
    "plot.imview(\n",
    "    ...,\n",
    "    title=\"Sinogram\",\n",
    "    cbar=None,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "divider = make_axes_locatable(ax[1])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "fig.colorbar(ax[1].get_images()[0], cax=cax, label=\"arbitrary units\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d15b11",
   "metadata": {},
   "source": [
    "Now, we repeat the proces to generate at least 24 different (foam, sinogram) pairs.\n",
    " **Start by generating the foams.**\n",
    "You'll need to make sure that you return an `ndarray`, not a `list`.\n",
    "The function `np.stack` may be useful for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4126d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nfoams = ...\n",
    "foam_collection = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2614d06",
   "metadata": {},
   "source": [
    "Run the next cell to plot the generated foams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79050e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nrows = 4\n",
    "ncols = 6\n",
    "fig, ax = plot.subplots(nrows=nrows, ncols=ncols, figsize=(15, 10))\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        plot.imview(foam_collection[i * ncols + j], cbar=None, fig=fig, ax=ax[i, j])\n",
    "    divider = make_axes_locatable(ax[i, j])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "    fig.colorbar(ax[i, j].get_images()[0], cax=cax, label=\"arbitrary units\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732135d",
   "metadata": {},
   "source": [
    "Operations can be accelerated by distributing processing among GPUs or CPUs. Depending on the environment, the distribution can happen automatically (e.g. GPUs in the same node), require setting a few flags (e.g. to use multiple CPU cores), or using further packages (e.g. ray or mpi4py for multinode).\n",
    "\n",
    "Running in Colab somewhat limits resources and exploitation of these options. Therefore, we will limit on this tutorial to run on only one CPU node, and reduce sizes of data sets, ML architectures, epochs, etc. Users are encouraged to look through the documentation and the usage examples demonstrating other distributed architectures.\n",
    "\n",
    "For example, next cell has commented out the commands that would be useful to exploit multiple cores in a CPU. The only commands active are the ones that print the current configuration of the jax environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ab2c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "import jax\n",
    "\n",
    "#os.environ[\"XLA_FLAGS\"] = \"--xla_force_host_platform_device_count=8\"\n",
    "#platform = jax.lib.xla_bridge.get_backend().platform\n",
    "#print(\"Platform: \", platform)\n",
    "print(f\"{'JAX process: '}{jax.process_index()}{' / '}{jax.process_count()}\")\n",
    "print(f\"{'JAX local devices: '}{jax.local_devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aed876",
   "metadata": {},
   "source": [
    "For purely jax functionality, a distributed processing can be computed via `jax.vmap`. However, the CT operator uses a python (not JAX) library.\n",
    "In that case we can distribute the processing via `jax.lax`. Run the next cell to distribute the computation of the sinograms. (This would be efficient in an environment with multiple resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed753f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sino_collection = jax.lax.map(lambda x: A @ x, foam_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c54e23",
   "metadata": {},
   "source": [
    "**Check the shape of the result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d455d8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b281b5bf",
   "metadata": {},
   "source": [
    "**Explain the shape of `sino_collection`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bea18",
   "metadata": {},
   "source": [
    "The shape corresponds to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b594ab3",
   "metadata": {},
   "source": [
    "You are done with part 1. Please report back in the Webex chat: **done with part 1**.\n",
    "\n",
    "While you wait for others to finish, you could explore other SCICO linear operators that can be used to transform image data, e.g., `Convolve`.\n",
    "\n",
    "ðŸ›‘ **PAUSE HERE** ðŸ›‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c259c739",
   "metadata": {},
   "source": [
    "# Solving a regularized reconstruction: Data-Driven Priors\n",
    "\n",
    "When there is an explicit representation of the forward model, the signal reconstruction can be posed as\n",
    "a regularized least squares problem\n",
    "\n",
    "$$ \\min_\\mathbf{x} \\| \\mathbf{y} - A \\mathbf{x} \\|_2^2 + \\, \\lambda \\, r(\\mathbf{x}).$$\n",
    "\n",
    "For example, in the CT case, the forward model $A$ is the CT projector, the measurements are the sinograms $y$ and\n",
    "the solution $x$ represents the signal reconstruction. The constant $\\lambda > 0$, establishes the trade-off\n",
    "between the fidelity to the measurements and the regularization of the solution represented as $r(x)$.\n",
    "\n",
    "In many cases, the regularization is necessary to find a meaningful solution for ill-posed problems. The difficulty\n",
    "arises in specifying an efficient regularization criterion. Functions like TV are adequate for piece-wise constant\n",
    "solutions, but may be not expressive enough for more general cases. Frameworks like plug-and-play priors provide\n",
    "a convenient alternative for cases when denoisers implement appropriate artifact removal. A complementary\n",
    "strategy is to unroll the iterative optimization process and build a neural network model that can be trained\n",
    "end-to-end. This kind of pipeline also offers the benefit of rapid evaluation in deployment, although its\n",
    "performance will depend on the training data, as is usually the case in machine learning models.\n",
    "\n",
    "The following diagram illustrates the kind of ML structure we will be training for the CT reconstruction:\n",
    "\n",
    "![Unrolled end-to-end](../../examples/tutorial/unrolled.png \"Unrolled end-to-end\")\n",
    "\n",
    "In the diagram, the green blocks correspond to a denoiser, generally a residual convolutional neural network, and are trainable. The red blocks correspond to a data consistency block and use the forward and adjoint operators. We will be constructing and training one such unrolled model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24983eae",
   "metadata": {},
   "source": [
    "For this tutorial we will use the MoDL architecture.\n",
    "\n",
    "The class [flax.MoDLNet](../_autosummary/scico.learning.rst#scico.learning.MoDL)\n",
    " implements the MoDL architecture, which unrolls the optimization problem\n",
    "\n",
    "  $$\\mathrm{argmin}_{\\mathbf{x}} \\; \\| A \\mathbf{x} - \\mathbf{y} \\|_2^2 + \\lambda \\, \\| \\mathbf{x} - \\mathrm{D}_w(\\mathbf{x})\\|_2^2 \\;,$$\n",
    "\n",
    "where $A$ is a forward operator, in this case a CT projector, $\\mathbf{y}$ is a set of measurements, in this case a collection of sinograms, $\\mathrm{D}_w$ is the\n",
    " regularization (a denoiser), and $\\mathbf{x}$ is the set of reconstructed images.\n",
    "  The MoDL abstracts the iterative solution by an unrolled network where each iteration corresponds\n",
    "  to a different stage in the MoDL network and updates the prediction by solving\n",
    "\n",
    "  $$\\mathbf{x}^{k+1} = (A^T A + \\lambda \\, \\mathbf{I})^{-1} (A^T \\mathbf{y} + \\lambda \\, \\mathbf{z}^k) \\;,$$\n",
    "\n",
    "via conjugate gradient. In the expression, $k$ is the index of the stage (iteration),\n",
    " $\\mathbf{z}^k = \\mathrm{ResNet}(\\mathbf{x}^{k})$ is the regularization\n",
    " (a denoiser implemented as a residual convolutional neural network), $\\mathbf{x}^k$ is the output\n",
    "  of the previous stage, $\\lambda > 0$\n",
    "  is a learned regularization parameter, and $\\mathbf{I}$ is the identity operator.\n",
    "  The output of the final stage is the reconstructed image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a003d6",
   "metadata": {},
   "source": [
    "## Constructing the Data Sets\n",
    "\n",
    "Machine learning processing for images in Flax assumes the following data shape: $(K, H, W, C)$\n",
    "\n",
    "- $K$ is the number of image samples\n",
    "- $H$ is the height of the images\n",
    "- $W$ is the width of the images\n",
    "- $C$ is the number of channels of the images (e.g. 1 for grayscale images, 3 for color images)\n",
    "\n",
    "**Reformat the training data to have the expected Flax shape.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb14c9a5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foam_collection = foam_collection.reshape(...)\n",
    "sino_collection = sino_collection.reshape(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64bd094",
   "metadata": {},
   "source": [
    "SCICO passes the data to the ML models as a dictionary, with the `image` key to define the input and the `label` key to define the expected output. In other words, (`image`, `label`) define the pair needed for supervised training.\n",
    "\n",
    "**Construct training and testing partitions for the CT reconstuction problem**. Use the first 16 images for training and the rest for testing. Remember that in the CT problem you want to reconstruct images from sinograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49f5c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = {}\n",
    "test_ds = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898ce2e",
   "metadata": {},
   "source": [
    "## Configuring the ML model and its training\n",
    "\n",
    "SCICO configures both model and training via dictionaries too. An example of configuration dictionaries with the corresponding definitions is shown next.\n",
    "\n",
    "Run the next cell to build the configuration dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812176f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "model_conf = {\n",
    "    \"depth\": 2,  # Number of layers (=iterations) in the unrolled ML model\n",
    "    \"num_filters\": 16,  # Number of filters in the denoiser\n",
    "    \"block_depth\": 3,  # Number of layers in the denoiser\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "train_conf = {\n",
    "    \"opt_type\": \"ADAM\",  # Optimization (other available options: SGD, ADAMW)\n",
    "    \"batch_size\": 8,  # Number of samples to include in each batch\n",
    "    \"num_epochs\": 50,  # Number of training epochs\n",
    "    \"base_learning_rate\": 1e-2,  # Base learning rate\n",
    "    \"warmup_epochs\": 0,  # Iterations to reach the base learning rate (if a scheduler is specified)\n",
    "    \"log_every_steps\": 5,  # Frequency of reporting training stats, given in units of training steps\n",
    "    \"checkpointing\": False,  # Checkpoint stats during training\n",
    "    \"log\": True,  # Display training messages and statistics\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b65af6e",
   "metadata": {},
   "source": [
    "## Constructing the ML model\n",
    "\n",
    "SCICO ML functionality is based on FLAX (see https://flax.readthedocs.io/en/latest/overview.html). Frequently used models are provided in SCICO.\n",
    "\n",
    "Run the next cell to import the Flax functionality in SCICO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a93d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scico import flax as sflax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4711c",
   "metadata": {},
   "source": [
    "**Look how to construct a MoDL model in the SCICO documentation and construct it.** Use the parameters already defined, but use 1 as depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c95e6a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "channels = ...\n",
    "model = sflax.MoDLNet(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bc0af",
   "metadata": {},
   "source": [
    "You are done with part 2. Please report back in the Webex chat: **done with part 2**.\n",
    "\n",
    "While you wait for others to finish, explore other ML models available in SCICO.\n",
    "\n",
    "ðŸ›‘ **PAUSE HERE** ðŸ›‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1019c80",
   "metadata": {},
   "source": [
    "# Training the MoDL model\n",
    "\n",
    "$\\lambda$, the regularization parameter in MoDL, is also learned in the training process. However, it is important that it remains positive.\n",
    "\n",
    "Run the next cell to build the structure necessary to assure that the training will respect such constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7331b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from scico.flax.train.train import clip_positive, construct_traversal\n",
    "\n",
    "lmbdatrav = construct_traversal(\n",
    "    \"lmbda\"\n",
    ")  # Functionality to get parameter to constraint inside model\n",
    "lmbdapos = partial(\n",
    "    clip_positive,  # Type of constraint to apply, here positivity constraint\n",
    "    traversal=lmbdatrav, # Operate over lmbda parameters\n",
    "    minval=5e-4,  # Minimum value to accept when enforcing the positivity constraint\n",
    ")\n",
    "\n",
    "train_conf[\"post_lst\"] = [lmbdapos]  # Constraints to model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ceaac",
   "metadata": {},
   "source": [
    "Now that we have all the structures needed for training: a data set, a model, and parameter constraints, we can use SCICO to train the model.\n",
    "\n",
    "All the training in SCICO is carried out through the `BasicFlaxTrainer` class. The following cell shows how to instantiate an object of that class. It uses an MSE loss function as minimization criterion by default (so it is not necessary to pass it explicitly). Look into the documentation and compare with the arguments provided.\n",
    "\n",
    "Run the next cell to train the model for the number of epochs specified. Check the output being produced. It corresponds, first, to the variables of the model and, next, to the training statistics. If it is taking too long, you can try to train for less epochs or use less layers in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4a012",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "trainer = sflax.BasicFlaxTrainer(\n",
    "    train_conf,  # Dictionary with training configuration\n",
    "    model,  # Model to train\n",
    "    train_ds,  # Data set for training (image-label dictionary)\n",
    "    test_ds,  # Data set for testing (image-label dictionary)\n",
    ")\n",
    "start_time = time()\n",
    "modvar, stats_object_ini = trainer.train()\n",
    "time_train = time() - start_time\n",
    "print(f\"Time train [s]: {time_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d17eab3",
   "metadata": {},
   "source": [
    "Run the next cell to plot the training statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26dde0b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hist = stats_object_ini.history(transpose=True)\n",
    "fig, ax = plot.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
    "plot.plot(\n",
    "    np.vstack((hist.Train_Loss, hist.Eval_Loss)).T,\n",
    "    x=hist.Epoch,\n",
    "    ptyp=\"semilogy\",\n",
    "    title=\"Loss function\",\n",
    "    xlbl=\"Epoch\",\n",
    "    ylbl=\"Loss value\",\n",
    "    lgnd=(\"Train\", \"Test\"),\n",
    "    fig=fig,\n",
    "    ax=ax[0],\n",
    ")\n",
    "\n",
    "plot.plot(\n",
    "    np.vstack((hist.Train_SNR, hist.Eval_SNR)).T,\n",
    "    x=hist.Epoch,\n",
    "    title=\"Metric\",\n",
    "    xlbl=\"Epoch\",\n",
    "    ylbl=\"SNR (dB)\",\n",
    "    lgnd=(\"Train\", \"Test\"),\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3147fe5e",
   "metadata": {},
   "source": [
    "The MoDL architecture shares the parameters between the different iteration layers. The previous training was the initialization and used only one layer (corresponding to only unrolling one iteration of the optimization computation). Now we can train the model with the specified depth (from `model_conf`).\n",
    "\n",
    "**Repeat the training process**, but this time use the configured depth, 10 cg iterations and initialize with the current model parameters. Train for 10 epochs.\n",
    "In addition, set an exponentially decaying learning rate by\n",
    " adding a `create_lr_schedule` and a decay rate of 0.5 to the training configuration dictionary. Create a new trainer object. Make sure you pass the parameter `variables0=modvar` when initializing the object to start training with your pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98e290",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scico.flax.train.train import create_exp_lr_schedule\n",
    "\n",
    "model.depth = ...\n",
    "model.cg_iter = ...\n",
    "train_conf[\"num_epochs\"] = ...\n",
    "train_conf[\"lr_decay_rate\"] = ...\n",
    "train_conf[\"create_lr_schedule\"] = ...\n",
    "train_conf[\"post_lst\"] = ...\n",
    "\n",
    "trainer = ...\n",
    "start_time = time()\n",
    "modvar, stats_object = ...\n",
    "time_train = time() - start_time\n",
    "print(f\"Time train [s]: {time_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acff3cd6",
   "metadata": {},
   "source": [
    "Plot the training stats for this last training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1be3eb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e91ed",
   "metadata": {},
   "source": [
    "You are done with part 3. Please report back in the Webex chat: **done with part 3**.\n",
    "\n",
    "While you wait for others to finish, think of things you could try\n",
    " to improve the performance of MoDL for CT reconstruction.\n",
    "\n",
    "ðŸ›‘ **PAUSE HERE** ðŸ›‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fe3c45",
   "metadata": {},
   "source": [
    "# Deploying a trained model\n",
    "\n",
    "If all you need to do is to apply a trained model, SCICO provides the `FlaxMap` class. This also allows you to connect trained models to other SCICO functionality.\n",
    "\n",
    "Run the next cell to see the trained model applied to the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972be60f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "fmap = sflax.FlaxMap(model, modvar)\n",
    "output = fmap(test_ds[\"image\"])\n",
    "time_eval = time() - start_time\n",
    "output = np.clip(output, a_min=0, a_max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f4834",
   "metadata": {},
   "source": [
    "Use the SCICO documentation to figure out how to **compute SNR and MAE for the reconstructions obtained with MoDL**.\n",
    "You might start looking in https://scico.readthedocs.io/en/latest/_autosummary/scico.metric.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ad3e0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scico import metric\n",
    "\n",
    "snr_eval = ...\n",
    "mae_eval = ...\n",
    "print(f\"SNR [dB]: {snr_eval}\")\n",
    "print(f\"MAE: {mae_eval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43892ff6",
   "metadata": {},
   "source": [
    "Run the next cell to check one of the testing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b400b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(543)\n",
    "indx = np.random.randint(0, high=8)\n",
    "\n",
    "fig, ax = plot.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "plot.imview(test_ds[\"label\"][indx, ..., 0], title=\"Ground truth\", cbar=None, fig=fig, ax=ax[0])\n",
    "plot.imview(\n",
    "    test_ds[\"image\"][indx, ..., 0],\n",
    "    title=\"Sinogram\",\n",
    "    cbar=None,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "plot.imview(\n",
    "    output[indx, ..., 0],\n",
    "    title=\"MoDL Reconstruction\\nSNR: %.2f (dB), MAE: %.3f\"\n",
    "    % (\n",
    "        metric.snr(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "        metric.mae(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "    ),\n",
    "    fig=fig,\n",
    "    ax=ax[2],\n",
    ")\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "fig.colorbar(ax[2].get_images()[0], cax=cax, label=\"arbitrary units\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6444df",
   "metadata": {},
   "source": [
    "You are done with part 4. Please report back in the Webex chat: **done with part 4**.\n",
    "\n",
    "While you wait for others to finish, think why you need to provide both model and variables when constructing the FlaxMap class.\n",
    "\n",
    "ðŸ›‘ **PAUSE HERE** ðŸ›‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95151737",
   "metadata": {},
   "source": [
    "## UQ/ML\n",
    "A basic UQ/ML model is to perform aletoric analysis and assume that the output (predictions) are independently and normally distributed. We can build a model to simultaneosuly predict mean and variance of the (independent) outputs.\n",
    "\n",
    "The corresponding loss function, denominated a heteroscedastic loss, can be expressed as\n",
    "\n",
    "$$L_{\\mathrm{het}} = \\frac{1}{N} \\sum_i \\frac{1}{2 \\sigma(\\mathbf{x_i})^2} || \\mathbf{y_i} - f(\\mathbf{x_i}) ||^2 + \\frac{1}{2} \\log \\sigma(\\mathbf{x_i})^2;,$$\n",
    "\n",
    "with $f(\\mathbf{x_i})$ the mean prediction and $\\sigma(\\mathbf{x_i})^2$ the variance.\n",
    "\n",
    "Run the next cell to define the heteroscedastic loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d2f703",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def het_loss(predictions, targets):\n",
    "    diff_sq = (targets - predictions[..., [0]])**2\n",
    "    log_sig2 = predictions[..., [1]]\n",
    "\n",
    "    return jnp.mean(jnp.exp(-log_sig2) * diff_sq + log_sig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dfdaf8",
   "metadata": {},
   "source": [
    "Build a MoDL model that can use the heteroscedastic loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d19e92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from jax import lax\n",
    "from typing import Any, Tuple\n",
    "from flax.linen.module import Module, compact\n",
    "from scico.flax import ResNet\n",
    "from scico.flax.inverse import cg_solver\n",
    "from scico.metric import snr\n",
    "from scico.typing import Array, DType, PRNGKey, Shape\n",
    "\n",
    "class MoDLNet_het(Module): ...\n",
    "def compute_metrics_het(output, labels, criterion): ...\n",
    "\n",
    "model = MoDLNet_het(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a9fad7",
   "metadata": {},
   "source": [
    "Train the model as you did with previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91870403",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_conf = {...}\n",
    "\n",
    "trainer = sflax.BasicFlaxTrainer(...)\n",
    "start_time = time()\n",
    "modvar, stats_object = trainer.train()\n",
    "time_train = time() - start_time\n",
    "print(f\"Time train [s]: {time_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f019f2f",
   "metadata": {},
   "source": [
    "Run the next cell to check one of the testing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c84982",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fmap = sflax.FlaxMap(model, modvar)\n",
    "output = fmap(test_ds[\"image\"])\n",
    "\n",
    "np.random.seed(543)\n",
    "indx = np.random.randint(0, high=8)\n",
    "# extract standard deviation\n",
    "std_indx = jnp.sqrt(jnp.exp(output[indx, ..., 1]))\n",
    "\n",
    "fig, ax = plot.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "plot.imview(test_ds[\"label\"][indx, ..., 0], title=\"Ground truth\", cbar=None, fig=fig, ax=ax[0])\n",
    "\n",
    "plot.imview(\n",
    "    output[indx, ..., 0],\n",
    "    title=\"MoDL Reconstruction\\nSNR: %.2f (dB), MAE: %.3f\"\n",
    "    % (\n",
    "        metric.snr(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "        metric.mae(test_ds[\"label\"][indx, ..., 0], output[indx, ..., 0]),\n",
    "    ),\n",
    "    cbar=None,\n",
    "    fig=fig,\n",
    "    ax=ax[1],\n",
    ")\n",
    "plot.imview(std_indx, title=\"Standard Deviation\", fig=fig, ax=ax[2])\n",
    "\n",
    "divider = make_axes_locatable(ax[2])\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "fig.colorbar(ax[2].get_images()[0], cax=cax, label=\"arbitrary units\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d65ab8",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This tutorial has shown how to set up\n",
    "a SCICO pipeline for performing computed tomography (CT) reconstruction using data-driven priors. In doing so, it has demonstrated SCICO functionality to build and train ML models for imaging problems. The functionality is based on FLAX and provides a  straightforward pipeline for other ML applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e6946",
   "metadata": {},
   "source": [
    "You are done with this tutorial! Please report back in the Webex chat: **done with the CNN tutorial**.\n",
    "\n",
    "While you wait for others to finish, you could think of similar problems you may want to solve with SCICO.\n",
    "We would be happy to talk with you about using SCICO in your own work!"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
